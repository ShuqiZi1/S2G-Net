#!/usr/bin/env python3
"""
Publishable-level visualization for S²G-Net hyperparameter sensitivity analysis
Generates publication-ready figures for ICU length-of-stay prediction results
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json
from scipy import stats

# Publication-quality settings
plt.rcParams.update({
    'font.size': 12,
    'font.family': 'sans-serif',
    'font.sans-serif': ['Arial', 'Helvetica', 'DejaVu Sans', 'sans-serif'],
    'axes.linewidth': 0.8,
    'axes.spines.left': True,
    'axes.spines.bottom': True,
    'axes.spines.top': True,
    'axes.spines.right': True,
    'xtick.major.size': 5,
    'xtick.minor.size': 3,
    'ytick.major.size': 5,
    'ytick.minor.size': 3,
    'legend.frameon': True,
    'figure.dpi': 300,
    'savefig.dpi': 300,
    'savefig.bbox': 'tight',
    'savefig.pad_inches': 0.1,
    'grid.alpha': 0.3,
    'grid.linewidth': 0.5,
    'axes.titlesize': 13,
    'axes.labelsize': 12,
    'xtick.labelsize': 11,
    'ytick.labelsize': 11,
    'legend.fontsize': 11,
})

# Academic color palette matching tracking_viz
ACADEMIC_COLORS = [
    '#E74C3C',  # R:231, G:98, B:84 - Red-orange
    '#EF7F39',  # R:239, G:138, B:71 - Orange  
    '#F7AF58',  # R:247, G:170, B:88 - Light orange
    '#FFD166',  # R:255, G:208, B:111 - Yellow
    '#FFF2B7',  # R:255, G:230, B:183 - Light yellow
    '#AADCE0',  # R:170, G:220, B:224 - Light blue
    '#72BFCF',  # R:114, G:188, B:213 - Medium blue
    '#4F8DA6',  # R:082, G:143, B:173 - Blue
    '#37679F',  # R:055, G:103, B:149 - Dark blue
    '#1E3A5F'   # R:030, G:070, B:110 - Very dark blue
]

# Specialized colors for highlighting (matching tracking_viz)
COLORS = {
    'highlight': '#E74C3C',    # Red-orange for S²G-Net (most prominent)
    'primary': '#4F8DA6',      # Blue for primary elements
    'secondary': '#37679F',    # Dark blue for secondary
    'neutral': '#72BFCF',      # Medium blue for neutral
    'background': '#F8F9FA',   # Light background
}

class S2GNetVisualization:
    """Publication-ready visualization for S²G-Net hyperparameter analysis"""
    
    def __init__(self, results_dir="results/hyperparameter", output_dir="figures"):
        self.results_dir = Path(results_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Load analysis results
        self.load_data()
        
    def load_data(self):
        """Load all analysis result files"""
        print("Loading hyperparameter analysis results...")
        
        # Load main results
        self.trials_df = pd.read_csv(self.results_dir / "trial_results.csv")
        self.param_importance_df = pd.read_csv(self.results_dir / "parameter_importance.csv")
        self.optimization_history_df = pd.read_csv(self.results_dir / "optimization_history.csv")
        
        # Filter out failed trials (val_r2 = 0 or NaN)
        original_count = len(self.trials_df)
        self.trials_df = self.trials_df[(self.trials_df['val_r2'] > 0) & 
                                       (self.trials_df['val_r2'].notna())]
        
        original_opt_count = len(self.optimization_history_df)
        self.optimization_history_df = self.optimization_history_df[
            (self.optimization_history_df['val_r2'] > 0) & 
            (self.optimization_history_df['val_r2'].notna())
        ]
        
        # Load best parameters
        with open(self.results_dir / "best_parameters.json", 'r') as f:
            self.best_results = json.load(f)
            
        print(f"Loaded {len(self.trials_df)} valid trials (filtered {original_count - len(self.trials_df)} failed trials)")
        print(f"Optimization history: {len(self.optimization_history_df)} valid trials (filtered {original_opt_count - len(self.optimization_history_df)} failed trials)")
        print(f"Best validation R²: {self.best_results['best_value']:.4f}")
        
    def create_hyperparameter_importance_plot(self):
        """Create professional hyperparameter importance visualization"""
        fig, ax = plt.subplots(1, 1, figsize=(10, 6))
        
        # Sort parameters by importance
        importance_sorted = self.param_importance_df.sort_values('importance', ascending=True)
        
        # Customize labels - make them more readable
        param_labels = {
            'mamba_d_model': 'Mamba Hidden Dim',
            'mamba_layers': 'Mamba Layers', 
            'mamba_d_state': 'Mamba State Dim',
            'mamba_dropout': 'Mamba Dropout',
            'mamba_pooling': 'Mamba Pooling',
            'gps_layers': 'GPS Layers',
            'gps_dropout': 'GPS Dropout',
            'lg_alpha': 'Fusion Weight α',
            'lr': 'Learning Rate',
            'batch_size': 'Batch Size',
            'clip_grad': 'Gradient Clipping'
        }
        
        readable_labels = [param_labels.get(param, param) 
                          for param in importance_sorted['parameter']]
        
        # Create horizontal bar plot
        y_pos = np.arange(len(importance_sorted))
        bars = ax.barh(y_pos, importance_sorted['importance'],
                      color=COLORS['primary'],
                      alpha=0.8,
                      edgecolor='white',
                      linewidth=0.8,
                      height=0.7)
        
        ax.set_yticks(y_pos)
        ax.set_yticklabels(readable_labels, fontsize=12)
        ax.set_xlabel('Hyperparameter Importance', fontsize=12)
        
        # Add value labels on bars
        for i, (bar, value) in enumerate(zip(bars, importance_sorted['importance'])):
            ax.text(value + importance_sorted['importance'].max() * 0.02, 
                   bar.get_y() + bar.get_height()/2, 
                   f'{value:.3f}', ha='left', va='center', fontsize=11)
        
        # Customize grid
        ax.grid(axis='x', alpha=0.25, linestyle='-', linewidth=0.4)
        ax.set_axisbelow(True)
        
        # Keep all spines for professional look
        for spine in ax.spines.values():
            spine.set_linewidth(0.8)
        
        # Set limits with padding
        ax.set_xlim(0, importance_sorted['importance'].max() * 1.15)
        
        plt.tight_layout()
        
        # Save figure
        fig_path = self.output_dir / "hyperparameter_importance.pdf"
        plt.savefig(fig_path, format='pdf', facecolor='white', bbox_inches='tight')
        plt.savefig(self.output_dir / "hyperparameter_importance.png", format='png', facecolor='white', bbox_inches='tight')
        
        print(f"Hyperparameter importance plot saved: {fig_path}")
        plt.show()
        
    def create_optimization_convergence_plot(self):
        """Create optimization convergence visualization"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # Left panel: Optimization history with moving average
        trials = self.optimization_history_df['trial_number'].values
        r2_scores = self.optimization_history_df['val_r2'].values
        
        # Calculate running best (cumulative maximum)
        running_best = np.maximum.accumulate(r2_scores)
        
        # Calculate moving average (window=20)
        window = min(20, len(r2_scores)//5)
        moving_avg = pd.Series(r2_scores).rolling(window=window, min_periods=1).mean()
        
        # Plot individual trials (lighter)
        ax1.scatter(trials, r2_scores, 
                   alpha=0.4, s=20, color=COLORS['neutral'], 
                   label='Individual Trials')
        
        # Plot moving average
        ax1.plot(trials, moving_avg, 
                color=ACADEMIC_COLORS[1], linewidth=2.5, 
                label=f'Moving Average (n={window})')
        
        # Plot running best
        ax1.plot(trials, running_best, 
                color=COLORS['primary'], linewidth=3, 
                label='Best Score')
        
        ax1.set_xlabel('Trial Number', fontsize=12)
        ax1.set_ylabel('Validation R²', fontsize=12)
        ax1.set_title('(a) Hyperparameter Optimization Convergence', fontsize=13)
        ax1.grid(True, alpha=0.25, linestyle='-', linewidth=0.4)
        ax1.legend(loc='lower right', fontsize=11, frameon=True, framealpha=0.95,
                  edgecolor='lightgray', fancybox=False, shadow=False)
        
        # Keep all spines for professional look
        for spine in ax1.spines.values():
            spine.set_linewidth(0.8)
        
        # Right panel: Performance distribution
        ax2.hist(r2_scores, bins=30, alpha=0.7, color=COLORS['primary'], 
                edgecolor='white', linewidth=0.8, density=True)
        
        # Add vertical line for best score
        best_score = running_best[-1]
        ax2.axvline(best_score, color=COLORS['highlight'], linestyle='--', 
                   linewidth=2.5, label=f'Best: {best_score:.4f}')
        
        # Add vertical line for mean
        mean_score = np.mean(r2_scores)
        ax2.axvline(mean_score, color=ACADEMIC_COLORS[1], linestyle=':', 
                   linewidth=2.5, label=f'Mean: {mean_score:.4f}')
        
        ax2.set_xlabel('Validation R²', fontsize=12)
        ax2.set_ylabel('Density', fontsize=12)
        ax2.set_title('(b) Performance Distribution', fontsize=12)
        ax2.grid(True, alpha=0.25, linestyle='-', linewidth=0.4)
        ax2.legend(fontsize=10, frameon=True, framealpha=0.95,
                  edgecolor='lightgray', fancybox=False, shadow=False)
        
        # Keep all spines for professional look
        for spine in ax2.spines.values():
            spine.set_linewidth(0.8)
        
        plt.tight_layout()
        
        # Save figure
        fig_path = self.output_dir / "optimization_convergence.pdf"
        plt.savefig(fig_path, format='pdf', facecolor='white', bbox_inches='tight')
        plt.savefig(self.output_dir / "optimization_convergence.png", format='png', facecolor='white', bbox_inches='tight')
        
        print(f"Optimization convergence plot saved: {fig_path}")
        plt.show()
        
    def create_performance_summary_table(self):
        """Create LaTeX table with key results"""
        # Get top 5 trials
        top_trials = self.trials_df.nlargest(5, 'val_r2')
        
        # Create summary statistics
        stats = {
            'Best R²': f"{self.best_results['best_value']:.4f}",
            'Mean R²': f"{self.trials_df['val_r2'].mean():.4f}",
            'Std R²': f"{self.trials_df['val_r2'].std():.4f}",
            'Total Trials': f"{len(self.trials_df)}",
            'Top 10% Mean': f"{self.trials_df.nlargest(len(self.trials_df)//10, 'val_r2')['val_r2'].mean():.4f}"
        }
        
        # Save LaTeX table
        latex_table = """
\\begin{table}[h!]
\\centering
\\caption{S²G-Net Hyperparameter Optimization Results for ICU LOS Prediction}
\\label{tab:hyperparam_results}
\\begin{tabular}{lc}
\\toprule
\\textbf{Metric} & \\textbf{Value} \\\\
\\midrule
"""
        
        for metric, value in stats.items():
            latex_table += f"{metric} & {value} \\\\\n"
            
        latex_table += """\\bottomrule
\\end{tabular}
\\end{table}
"""
        
        with open(self.output_dir / "results_table.tex", 'w') as f:
            f.write(latex_table)
            
        print("LaTeX table saved: results_table.tex")
        return stats
        
    def generate_latex_figure_code(self):
        """Generate LaTeX code for including figures"""
        latex_code = """
% Figure 1: Hyperparameter Importance
\\begin{figure}[t!]
\\centering
\\includegraphics[width=0.9\\textwidth]{figures/hyperparameter_importance.pdf}
\\caption{Hyperparameter sensitivity analysis for S²G-Net on ICU length-of-stay prediction. 
Error bars represent bootstrap confidence intervals (100 samples). 
Mamba architectural parameters show highest sensitivity to model performance.}
\\label{fig:hyperparam_importance}
\\end{figure}

% Figure 2: Optimization Convergence  
\\begin{figure}[t!]
\\centering
\\includegraphics[width=\\textwidth]{figures/optimization_convergence.pdf}
\\caption{Hyperparameter optimization convergence for S²G-Net. 
(a) Evolution of validation R² across optimization trials. 
(b) Distribution of performance across all trials.}
\\label{fig:optimization_convergence}
\\end{figure}
"""
        
        with open(self.output_dir / "latex_figures.tex", 'w') as f:
            f.write(latex_code)
            
        print("LaTeX figure code saved: latex_figures.tex")
        
    def create_top_trials_table(self, top_n=10):
        """Create table with top N trials showing hyperparameters and metrics"""
        # Get top N trials by val_r2
        top_trials = self.trials_df.nlargest(top_n, 'val_r2').reset_index(drop=True)
        
        # Select key columns for the table
        key_params = ['mamba_d_model', 'mamba_layers', 'gps_layers', 'lg_alpha', 'lr']
        key_metrics = ['val_r2', 'mse', 'mad', 'kappa']
        
        # Create formatted table
        formatted_data = []
        for idx, row in top_trials.iterrows():
            trial_data = {'Rank': idx + 1}
            
            # Add hyperparameters
            for param in key_params:
                if param in row:
                    if param == 'lr':
                        trial_data[param] = f"{row[param]:.1e}"
                    elif param == 'lg_alpha':
                        trial_data[param] = f"{row[param]:.2f}"
                    else:
                        trial_data[param] = row[param]
            
            # Add metrics
            for metric in key_metrics:
                if metric in row and pd.notna(row[metric]):
                    if metric == 'val_r2' or metric == 'kappa':
                        trial_data[metric] = f"{row[metric]:.4f}"
                    else:
                        trial_data[metric] = f"{row[metric]:.3f}"
                else:
                    trial_data[metric] = "N/A"
            
            formatted_data.append(trial_data)
        
        # Convert to DataFrame
        top_trials_df = pd.DataFrame(formatted_data)
        
        # Rename columns for better presentation
        column_names = {
            'mamba_d_model': 'Mamba Dim',
            'mamba_layers': 'Mamba Layers', 
            'gps_layers': 'GPS Layers',
            'lg_alpha': 'Fusion α',
            'lr': 'Learning Rate',
            'val_r2': 'R²',
            'mse': 'MSE',
            'mad': 'MAD',
            'kappa': 'Kappa'
        }
        top_trials_df = top_trials_df.rename(columns=column_names)
        
        # Save as CSV
        csv_path = self.output_dir / f"top_{top_n}_trials.csv"
        top_trials_df.to_csv(csv_path, index=False)
        
        # Generate LaTeX table
        latex_table = f"""
\\begin{{table}}[h!]
\\centering
\\caption{{Top {top_n} Hyperparameter Configurations for S²G-Net ICU LOS Prediction}}
\\label{{tab:top_trials}}
\\resizebox{{\\textwidth}}{{!}}{{%
\\begin{{tabular}}{{c|cccc|cccc}}
\\toprule
\\textbf{{Rank}} & \\textbf{{Mamba Dim}} & \\textbf{{Mamba Layers}} & \\textbf{{GPS Layers}} & \\textbf{{Fusion α}} & \\textbf{{R²}} & \\textbf{{MSE}} & \\textbf{{MAD}} & \\textbf{{Kappa}} \\\\
\\midrule
"""
        
        for _, row in top_trials_df.iterrows():
            latex_table += f"{row['Rank']} & {row.get('Mamba Dim', 'N/A')} & {row.get('Mamba Layers', 'N/A')} & {row.get('GPS Layers', 'N/A')} & {row.get('Fusion α', 'N/A')} & {row['R²']} & {row.get('MSE', 'N/A')} & {row.get('MAD', 'N/A')} & {row.get('Kappa', 'N/A')} \\\\\n"
            
        latex_table += """\\bottomrule
\\end{tabular}%
}
\\end{table}
"""
        
        # Save LaTeX table
        latex_path = self.output_dir / f"top_{top_n}_trials_table.tex"
        with open(latex_path, 'w') as f:
            f.write(latex_table)
            
        print(f"Top {top_n} trials table saved:")
        print(f"  CSV: {csv_path}")
        print(f"  LaTeX: {latex_path}")
        
        return top_trials_df
        
    def create_all_visualizations(self, top_n=10):
        """Generate all publication-ready visualizations"""
        print("=" * 60)
        print("GENERATING S²G-NET PUBLICATION VISUALIZATIONS")
        print("=" * 60)
        
        # Create top trials table first
        top_trials_df = self.create_top_trials_table(top_n)
        print()
        
        # Create visualizations
        self.create_hyperparameter_importance_plot()
        print()
        
        self.create_optimization_convergence_plot()
        print()
        
        # Create summary table
        stats = self.create_performance_summary_table()
        print()
        
        # Generate LaTeX code
        self.generate_latex_figure_code()
        print()
        
        print("=" * 60)
        print("SUMMARY OF RESULTS")
        print("=" * 60)
        for metric, value in stats.items():
            print(f"{metric:15}: {value}")
        
        print(f"\nFigures saved to: {self.output_dir}")
        print(f"Top {top_n} trials table generated")
        print("Ready for publication! 🎉")


def main():
    """Main execution function"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Generate publication-ready S²G-Net visualizations")
    parser.add_argument('--results_dir', type=str, default="results/hyperparameter",
                       help="Directory containing hyperparameter analysis results")
    parser.add_argument('--output_dir', type=str, default="results/hyperparameter/hyper_viz", 
                       help="Output directory for generated figures")
    parser.add_argument('--top_n', type=int, default=10,
                       help="Number of top trials to include in table")
    
    args = parser.parse_args()
    
    # Create visualizer and generate all plots
    visualizer = S2GNetVisualization(args.results_dir, args.output_dir)
    visualizer.create_all_visualizations(args.top_n)


if __name__ == "__main__":
    main()